---
title: "Martha_paga_rxlr_workbook"
output: html_document
date: "2023-08-04"
---
### Martha's notes in real time-not polished at this point (will revise later)
### Can we try to install and set up all package before getting to individual code chunks? 

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library("seqinr")
library("tidyverse")
devtools::load_all('~/software/effectR-nick_edits/')
library('effectR')
devtools::load_all("~/software/iSecrete-master/")
library('iSecrete')
source("scripts/secretion_funcs.R")
library("optparse")
```

### Notes
To install EMBOSS I used following command on Linux computer:  'sudo apt install emboss'  
NOTE-to define 'isolate' variable-needed to fix suffix to -s rather than -suffix, or else there were errors  
When I install tmhmm from DTU health, I get this note:  
NOTE: TMHMM-2.0 is outdated. A more recent and better transmembrane predictor, DeepTMHMM, has beenreleased and is available at https://services.healthtech.dtu.dk/service.php?DeepTMHMM. 

### Things to clarify  
Make clear what version of signalP. V 3.0 is mentioned once in instruction but not explicitely, but the latest version is 5--so you do have to dig for an earlier version.

# Downloaded SignalP3.0 from same source-dtu.dk site.  
Something to maybe share with beginner users-Install instructions are in READMES and nowhere online! 

### Early error logs and trouble shooting
seq_analysis_utils-where is this? I cannot automatically import this using rxlr_signalpeptide.py script  
It turns out that this is where you do need to use python2.7.  I used pip to install v 2.7.  

I also needed several other packages but it wasn't entirely clear until I started running the scripts; this is a bit clunky using Rmarkdown. Maybe a readme file is preferable with the code chunks--I'll see as I go.  


#Weirdly couldn't run second set of commands in separate code chunks-so that is why there is one large code chunk. 

### Step 1 and Step 2
```{bash, eval = TRUE}
#Step 1
mkdir output_data
genome="data/Paga_3770v2_chr10.fasta"
#Note for signalP I had to copy signalp to /usr/bin. This was key for getting it to work
isolate=$(basename -s ".fasta" ${genome})
minsize_aa=70 # amino acids
minsize_nt=210 # minsize_aa*3 = number of nucleotides
orfs_name="${isolate}.orfs-min${minsize_aa}long.start2stop"
orfs="output_data/${orfs_name}.fasta"

getorf -sequence "$genome" -outseq "$orfs" -minsize $minsize_nt --find 1

#Step 2-couldn't run in separate code chunk for some reason
threads=10
CMD="python2.7 scripts/rxlr_signalpeptide.py $orfs $threads \
	secretome output_data/${orfs_name}.rxlr_signalpep.out"
echo $CMD
eval $CMD

~/software/tmhmm-2.0c/bin/tmhmm -short $orfs > output_data/${orfs_name}.tmhmm.out

#step 3
hmmsearch --cpu 4 --seed 123 -T 0 --tblout output_data/${orfs_name}.rxlr_WYfold_hmm.out data/WY_fold.hmm $orfs > output_data/${orfs_name}.rxlr_WYfold_hmm.log

# simple list of candidates
egrep -v '^#' output_data/${orfs_name}.rxlr_WYfold_hmm.out | awk '{print $1}' > output_data/${orfs_name}.rxlr_WYfold_hmm.list
```

### Step 3
```{r eval = TRUE}
wy_list_regex <- "*.orfs-min70long.start2stop.rxlr_WYfold_hmm.list"
orfs_wys <-  list.files(path = "output_data//",
                                pattern = wy_list_regex, full.names = TRUE) %>%
  map_dfr(read_wy_list) %>%
  unite("ID_isolate", ID, isolate, sep=":", remove = FALSE) %>%
  mutate("method" = "WY_hmm")
```


### Step 4
```{r eval = TRUE}
# Locate files programmatically in R environment
# all ORFs:
orf_fs_re <- ".*orfs-min70long.start2stop.fasta"
orf_fs <- list.files(path = "output_data//",
                                pattern = orf_fs_re, full.names = TRUE) %>%
  tibble("orf_f" = .) %>%
  separate(orf_f, into = c("isolate", NA),
           sep = "(?=\\.orfs-min)", remove = FALSE) %>%
  mutate(isolate = str_remove(isolate, ".*data/*"))

# SignalP output files:
sp3_fs_re <- ".*orfs-min70long.start2stop.rxlr_signalpep.outsp3_tabular.tmp"
sp3_fs <- list.files(path = "output_data//",
                                pattern = sp3_fs_re, full.names = TRUE) %>%
  tibble("sp3_f" = .) %>%
  separate(sp3_f, into = c("isolate", NA),
           sep = "(?=\\.orfs-min)", remove = FALSE) %>%
  mutate(isolate = str_remove(isolate, ".*data/*"))

orf_sp3_fs <- full_join(orf_fs, sp3_fs, by = "isolate") %>%
  select(orf_f, sp3_f, isolate)

# run motif search
allorfs_re_effectr <- map2(orf_sp3_fs$orf_f, orf_sp3_fs$sp3_f, effectr_eer_sp3)

allorfs_re_effectr_tb <- tibble(bind_rows(allorfs_re_effectr)) %>%
  unite("ID_isolate", ID, isolate, sep=":", remove = FALSE)
```

### Step 5
```{r eval = TRUE}
sp3_fs_re <- ".*orfs-min70long.start2stop.rxlr_signalpep.outsp3_tabular.tmp"
sp3_fs <- list.files(path = "output_data/",
                                pattern = sp3_fs_re, full.names = TRUE)
tmm_fs_re <- ".*orfs-min70long.start2stop.tmhmm.out"
tmm_fs <- list.files(path= "output_data/",
                                pattern = tmm_fs_re, full.names = TRUE)

# make dataframe for easier function running
# and validate the signalp and tmhmm runs line up
sp3_tmm_fs <- tibble("sp3_f" = sp3_fs,
                     "tmm_f" = tmm_fs) %>%
  mutate("isolate_s" = str_extract(sp3_f, "(?<=//).*(?=\\.orfs)")) %>%
  mutate("isolate_t" = str_extract(tmm_f, "(?<=//).*(?=\\.orfs)"))

# parse signalP and tmhmm output files.
# filters based on HMM_Sprob_score of signalp
# and position of helix relative to most likely signal peptide position

#Error no proteins
sp3_tmm_pass <- pmap(sp3_tmm_fs, ~ read_prune_tms(..1, ..2, ..3), .id = 'isolate') %>%
  bind_rows() %>%
  unite("ID_isolate", Protein, isolate, sep=":", remove = FALSE)

# Size of complete secretome
sp3_tmm_pass %>%
  filter(HMM_Sprob_score >= 0.9) %>%
  distinct(ID_isolate, .keep_all = TRUE) %>%
  group_by(isolate) %>%
  summarize(n_noTM_yesSP = n())
```


### Step 6 
```{r eval = TRUE}
rxlr_orfs <- allorfs_re_effectr_tb %>% 
  bind_rows(orfs_wys) %>% # join to results of WY searching
  group_by(ID_isolate, ID, isolate) %>%
  mutate(isolate = str_remove(isolate, "/")) %>%
  # I want the methods as a list
  summarize(methods_list = paste(method, collapse = ",")) %>%
  filter((grepl("Whis2007", methods_list)) |
           (grepl("Whis_rxlr", methods_list) & (grepl("Whis_eer", methods_list) | grepl("WY_hmm", methods_list))) |
           (grepl("Win2007", methods_list) & (grepl("Whis_eer", methods_list) | grepl("WY_hmm", methods_list)))) %>%
  filter(ID_isolate %in% sp3_tmm_pass$ID_isolate) %>% # filter to secretome
  group_by(isolate) %>%
  distinct(ID_isolate)

# Final counts
rxlr_orfs %>%
  summarize(noTM_whis_or_whiswinrxlrEER_whiswinrxlrWY_count = n())

# Write final candidates to lists using respective isolate IDs
#remove temp

#additions
#outdir <- "output_data")
out_prefix <- "/orfs_cand_RXLRs_"

allorfs_re_effectr_tb %>%
  ungroup() %>%
  distinct(ID_isolate, .keep_all = TRUE) %>%
  select(ID, isolate) %>%
  group_by(isolate) %>%
  group_walk(~ writeLines(.x$ID, paste0("output_data", out_prefix, .y$isolate, ".txt")))
```

### Step 7 
### Requires AGAT, and need to fix path to assembly files
```{bash eval = TRUE}
#In bash environment, change directory names if needed
eval "$(conda shell.bash hook)"
conda activate agat
outdir="output_data"
#change
assembly_dir="data"
rxlr_prefix="orfs_cand_RXLRs_"
# Run on all genomes being annotated
for orf_rxlr_list in $(ls -1 $outdir/${rxlr_prefix}*.txt); do
  # Establish output file name conventions
  list_name=$(basename --suffix ".txt" $orf_rxlr_list)
  iso_name=$(echo $list_name | sed "s/$rxlr_prefix//")
  echo $iso_name
  assembly=$(ls ${assembly_dir}/${iso_name}.fasta) || \
    assembly=$(ls ${assembly_dir}/other_refs/${iso_name}.fasta)

  # If needed, replace 70 with minimum protein length chosen.
  orfs="$outdir/${iso_name}.orfs-min70long.start2stop.fasta"

  # Obtain nationality. First get long ORF names from abbreviated.
  grep -w -f $orf_rxlr_list $orfs | sed 's/>//' > $outdir/${list_name}_longnames.list
  # Next convert ORF tag list to GFF
  Rscript scripts/getorf_seqnames2gff.R -i $outdir/${list_name}_longnames.list

  # Notifies about overlapping genes
  agat_sp_fix_overlaping_genes.pl -f $outdir/${list_name}_longnames.gff \
  -o $outdir/${list_name}_longnames.merge_ovlp.gff
  
  # If genes need merging, pick ORFs by hand or use output from above
  agat_sp_add_start_and_stop.pl --gff $outdir/${list_name}_longnames.gff \
  --fasta $assembly \
  --output $outdir/${list_name}_longnames.str_stp.gff
done

```

### Step 8

```{bash eval = TRUE}
# Same code as Section 3.1 Step 7 to name variables and start loop
eval "$(conda shell.bash hook)"
conda activate agat
outdir="output_data"
assembly_dir="data"
rxlr_prefix="orfs_cand_RXLRs_"
# Run on all genomes being annotated
for orf_rxlr_list in $(ls -1 $outdir/${rxlr_prefix}*.txt); do
  # Establish output file name conventions
  list_name=$(basename --suffix ".txt" $orf_rxlr_list)
  iso_name=$(echo $list_name | sed "s/$rxlr_prefix//")
  echo $iso_name
  assembly=$(ls ${assembly_dir}/${iso_name}.fasta) || \
    assembly=$(ls ${assembly_dir}/other_refs/${iso_name}.fasta)

  # The next line of code needs to match FASTA file-naming convention to GFF.
  # As is, it converts "Plate_genome.fasta" to match "Plate_combine.gff" and 
  # "PR-102_v4.fasta" to match "PHRA102.gff"
  iso_prefix=$(echo $iso_name | sed 's/genome/combine/' | \
    sed 's/PR/PHRA/' | sed 's/-//g' | sed -e 's/_v.*//')

  # Re-name gene features
  agat_sp_manage_IDs.pl --tair --type_dependent \
    --prefix "${iso_prefix}_rxlrORF" \
    --nb 1 --gff $outdir/${list_name}_longnames.str_stp.gff \
    --output $outdir/${list_name}_longnames.str_stp.re-IDs.gff

  # TODO: Add gene supplementation code here.
done
```
